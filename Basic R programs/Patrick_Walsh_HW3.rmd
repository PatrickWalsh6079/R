# Intro to Data Science - HW 3
##### Copyright Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tacheva


```{r}
# Enter your name here: Patrick Walsh
```

### Attribution statement: (choose only one and delete the rest)


```{r}
# 1. I did this homework by myself, with help from the book and the professor.
```

### Reminders of things to practice from last week: 
Make a data frame		data.frame( ) <br>
Row index of max/min	which.max( )  which.min( )<br>
Sort value or order rows	sort( )   order( )<br>
Descriptive statistics 	mean( ) sum( ) max( ) <br>
Conditional statement	if (condition) “true stuff” else “false stuff”<br>

### This Week: 
Often, when you get a dataset, it is not in the format you want. You can (and should) use code to refine the dataset to become more useful. As Chapter 6 of Introduction to Data Science mentions, this is called “data munging.” In this homework, you will read in a dataset from the web and work on it (in a data frame) to improve its usefulness.


## Part 1: Use read_csv( ) to read a CSV file from the web into a data frame:

A.	Use R code to read directly from a URL on the web. Store the dataset into a new dataframe, called dfComps. <br>
The URL is:    <br>
"https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv" <br>
**Hint:** use read_csv( ), not read.csv( ). This is from the **tidyverse package**. Check the help to compare them.



```{r}
library(tidyverse)
dfComps <- read_csv("https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv")
```

## Part 2: Create a new data frame that only contains companies with a homepage URL:

E.	Use **subsetting** to create a new dataframe that contains only the companies with homepage URLs (store that dataframe in **urlComps**).


```{r}
urlComps <- dfComps[!(is.na(dfComps$homepage_url)),]
head(urlComps)
```

D.	How many companies are missing a homepage URL?


```{r}
nrow(dfComps[(is.na(dfComps$homepage_url)),])
```

## Part 3: Analyze the numeric variables in the dataframe.

G.	How many **numeric variables** does the dataframe have? You can figure that out by looking at the output of **str(urlComps)**. 

H.	What is the average number of funding rounds for the companies in **urlComps**?


```{r}
# G. 2
str(urlComps)

# H. 1.7
mean(urlComps$funding_rounds)
```

I.	What year was the oldest company in the dataframe founded? <br>
**Hint:** If you get a value of “NA,” most likely there are missing values in this variable which preclude R from properly calculating the min & max values. You can ignore NAs with basic math calculations. For example, instead of running mean(urlComps$founded_year), something like this will work for determining the average (note that this question needs to use a different function than 'mean'. 


```{r}
#mean(urlComps$founded_year, na.rm=TRUE)

min(urlComps$founded_year, na.rm=TRUE)
```

## Part 4:  Use string operations to clean the data.

K.	The **permalink variable** in **urlComps** contains the name of each company but the names are currently preceded by the prefix “/organization/”. We can use str_replace() in tidyverse or gsub() to clean the values of this variable:


```{r}
urlComps$permalink <- str_replace(urlComps$permalink, "/organization/", "")
head(urlComps)
```

L.	Can you identify another variable which should be numeric but is currently coded as character? Use the as.numeric() function to add a new variable to **urlComps** which contains the values from the char variable as numbers. Do you notice anything about the number of NA values in this new column compared to the original “char” one?  


```{r}
# The large number of NA values in this new column is due to the spaces in the original char column which prevents R from converting the char characters to numbers.

urlComps$funding_total_usd_NUM <- as.numeric(urlComps$funding_total_usd)
urlComps$funding_total_usd_NUM[1:500]
```

M.	To ensure the char values are converted correctly, we first need to remove the spaces between the digits in the variable. Check if this works, and explain what it is doing:


```{r}
# The code adds a new column to the urlComps dataframe by using the stri_replace_all_charclass() function. This function copies the 
# funding_total_usd column with spaces removed. The format for this function is:
# stri_replace_all_charclass(string, pattern, replacement)

library(stringi)
urlComps$funding_new <- stri_replace_all_charclass(urlComps$funding_total_usd,"\\p{WHITE_SPACE}", "")
urlComps$funding_new[1:500]
```


    Error in stri_replace_all_charclass(urlComps$funding_total_usd, "\\p{WHITE_SPACE}", : object 'urlComps' not found
    Traceback:


    1. stri_replace_all_charclass(urlComps$funding_total_usd, "\\p{WHITE_SPACE}", 
     .     "")


N. You are now ready to convert **urlComps$funding_new** to numeric using as.numeric(). 

Calculate the average funding amount for **urlComps**. If you get “NA,” try using the **na.rm=TRUE** argument from problem I.


```{r}
urlComps$funding_new_NUM <- as.numeric(urlComps$funding_new)
mean(urlComps$funding_new_NUM, na.rm=TRUE)
```

Sample three unique observations from urlComps$funding_rounds, store the results in the vector 'observations'


```{r}
observations <- sample(urlComps$funding_rounds, 3, replace=FALSE)
observations
```

Take the mean of those observations


```{r}
mean(observations)
```

Do the two steps (sampling and taking the mean) in one line of code


```{r}
mean(observations <- sample(urlComps$funding_rounds, 3, replace=FALSE))
```

Explain why the two means are (or might be) different

Use the replicate( ) function to repeat your sampling of three observations of urlComps$funding_rounds observations five times. The first argument to replicate( ) is the number of repeats you want. The second argument is the little chunk of code you want repeated.


```{r}
# In this case, the two means are different since they are random samplings of the vector. If we wanted to ensure that the samples
# are the same each time, we could use the set.seed() function to some numeric value, such as set.seed(5).

replicate(5, sample(urlComps$funding_rounds, 3, replace=FALSE))
```

Rerun your replication, this time doing 20 replications and storing the output of replicate() in a variable called **values**.


```{r}
values <- replicate(20, sample(urlComps$funding_rounds, 3, replace=FALSE))
```

Generate a **histogram** of the means stored in **values**. 


```{r}
hist(colMeans(values))
```

Rerun your replication, this time doing 1000 replications and storing the output of replicate() in a variable called **values**, and then generate a histogram of **values**.


```{r}
values <- replicate(1000, sample(urlComps$funding_rounds, 3, replace=FALSE))
hist(colMeans(values))
```

Repeat the replicated sampling, but this time, raise your sample size from 3 to 22. How does that affect your histogram? Explain in a comment.


```{r}
values <- replicate(1000, sample(urlComps$funding_rounds, 22, replace=FALSE))
hist(colMeans(values))

# Increasing the sample size helps to normalize the distribution of the histogram. Larger sampling helps to bring the values
# closer to the mean which improves the histogram distribution, as explained here: # https://medium.com/geekculture/how-increasing-sample-size-will-improve-gaussian-distribution-ae2bf5c5abaf
```

Explain in a comment below, the last three histograms, why do they look different?


```{r}
# The first two histograms are right skewed, where most of the data falls on the left side of the diagram. This is because
# the sample size is low, giving the column means low values on average. With the second histogram, there are more samples,
# making the skewness more even and the pattern more clear. It isn't until we get to the third histogram that we see the
# histogram start to become normalized since the sample sizes are increased, bringing the means closer to the center of the histogram.
```
